{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIASF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilW4XcCAaOTd",
        "colab_type": "text"
      },
      "source": [
        "# This Building Does Not Exist (Yet)\n",
        "\n",
        "## AIASF _NEXT_ 2019\n",
        "### Tyler Kvochick\n",
        "### TEECOM Research & Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf3BWrB0aoIt",
        "colab_type": "text"
      },
      "source": [
        "# Goals\n",
        "\n",
        "## Beyond Metaphors\n",
        "\n",
        "What is a neural network, literally?\n",
        "\n",
        "## Inner Workings\n",
        "\n",
        "What makes a neural network...work?\n",
        "\n",
        "## Applications\n",
        "\n",
        "What interesting models exist today and what can we make them do?\n",
        "\n",
        "(Hint: we can make sketchy floorplans)\n",
        "\n",
        "## Ultimately...\n",
        "\n",
        "To be unimpressed with machine learning jargon\n",
        "\n",
        "And to see machine learning as a practical tool rather than a mysterious buzzword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMg_xxxiqHrf",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "* All of this is happening in a remote Linux server\n",
        "* Under `Runtime` (above), select `Change Runtime Type` and set `Hardware Accelerator` to `GPU`\n",
        "* Use the demo cell to understand syntax & notebook environment\n",
        "* Install a network visualization module\n",
        "* Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z11hgKaNgwHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Demo cell!\n",
        "\n",
        "# Each light gray block (cell) can just be copied and pasted into the Colab notebook\n",
        "# Select the cell and hit Shift + Enter to execute it\n",
        "# The output for each cell will appear below it as it runs\n",
        "# When it is finished running, a number will appear in brackets at the far top left\n",
        "\n",
        "# The world's shortest Python tutorial:\n",
        "\n",
        "# Any text on a line after a `#` will be ignored as a code comment\n",
        "\n",
        "# Use `def` to define a reusable subroutine (function)\n",
        "def demo_function(name, number):\n",
        "    \n",
        "    # Assign values to identifiers with `=`\n",
        "    # Use double quotes `\"\"` to make a string\n",
        "    # Use `\"{}\".format(...some value...)` to put values into strings\n",
        "    message = \"Hello {}! Welcome to AIASF NEXT!\\n\".format(name)\n",
        "\n",
        "    # Do some math\n",
        "    x = 2\n",
        "    \n",
        "    # Raise x to the power that the user specifies with `number`\n",
        "    result = x ** number\n",
        "    \n",
        "    # Add that to our message\n",
        "    message += \"{} to the power of {} is {}\".format(x, number, result)\n",
        "    \n",
        "    # Print the message\n",
        "    print(message)\n",
        "    \n",
        "    # Give back the result of the math\n",
        "    return result\n",
        "\n",
        "# Use parentheses `()` after a function name to call it\n",
        "# Any arguments that it requires are put in order inside the parens\n",
        "some_power_of_two = demo_function(\"World\", 8)\n",
        "\n",
        "# The last value in the cell will be appended to the output\n",
        "some_power_of_two\n",
        "\n",
        "# Congrats! You are now a Python programmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whokGTbb5z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Commands prefixed with `!` are sent to the runtime's terminal emulator\n",
        "# Use the system package manager to install a non-standard module and hide the output\n",
        "\n",
        "!pip install torchviz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Pb2DroWfWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import a lot of packages for interacting with the filesystem,\n",
        "# doing math, working with images, and building neural networks\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnf\n",
        "import torch.optim as optim\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchviz import make_dot\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Configure the interactive plot size\n",
        "matplotlib.rcParams[\"figure.figsize\"] = (8, 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er15aE3zZppp",
        "colab_type": "text"
      },
      "source": [
        "# Beyond Metaphors\n",
        "\n",
        "What does a neural network look like?\n",
        "\n",
        "These are just concepts, we will look at literal versions in section 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE-Fay4AZ0kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Demo class just to see multiple representations of a neural network\n",
        "\n",
        "class NetworkVisualization(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetworkVisualization, self).__init__()\n",
        "        \n",
        "        # Add 2 sets of layers \n",
        "        # Set 0\n",
        "        self.conv0 = nn.Conv2d(3, 6, (3, 3), 2, 1)\n",
        "        self.act0 = nn.LeakyReLU()\n",
        "        # Set 1\n",
        "        self.conv1 = nn.Conv2d(3, 6, (3, 3), 2, 1)\n",
        "        self.act1 = nn.LeakyReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Use both sets of layers\n",
        "        x0 = self.act0(self.conv0(x))\n",
        "        x1 = self.act1(self.conv1(x))\n",
        "        \n",
        "        # Sum the result\n",
        "        return x0 + x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhlxDfhCX3lM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2742b280-7074-4652-e31a-25669d9295e2"
      },
      "source": [
        "# Create an instance of our class\n",
        "nv = NetworkVisualization().cuda()\n",
        "\n",
        "# Create a fake image made of white noise with the sizes: (1 image, 3 channels (RGB), 512 pixels high, 512 pixels wide)\n",
        "# Shapes are very important in deep learning\n",
        "fake_image = torch.randn(1, 3, 512, 512).cuda()\n",
        "\n",
        "# Use the created instance\n",
        "out = nv(fake_image)\n",
        "\n",
        "# Examine how the neural network changed the shape of our input\n",
        "print(\"Output shape: {}\".format(out.shape))\n",
        "\n",
        "# Print out the structure of our network\n",
        "print(nv)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([1, 6, 256, 256])\n",
            "NetworkVisualization(\n",
            "  (conv0): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (act0): LeakyReLU(negative_slope=0.01)\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (act1): LeakyReLU(negative_slope=0.01)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvk58yp0YJNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Render the graph\n",
        "make_dot(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g6AhXApZmEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the parameters\n",
        "# This is the most literal view of a neural network\n",
        "params = [p for p in list(nv.conv0.parameters())]\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "061DVh7-bSqg",
        "colab_type": "text"
      },
      "source": [
        "# No More Metaphors (Summary)\n",
        "\n",
        "## Multiple Representations of NNs\n",
        "\n",
        "1. As executable code / structured data (software)\n",
        "2. As a connective graph (visualization)\n",
        "3. As lists of numbers organized into rectilinear shapes (tensors)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfzLAltZneAz",
        "colab_type": "text"
      },
      "source": [
        "# Inner Workings\n",
        "\n",
        "We have seen that deep learning models are full of orthogonal collections of numbers that we call tensors. The rest of the model is made of mathematical functions for combining those tensors.\n",
        "\n",
        "## Convolution\n",
        "\n",
        "For working with images, the most common function for combining tensors in a learnable way is called convolution.\n",
        "\n",
        "Convolution is a confusing name for \"searching for known patterns\".\n",
        "\n",
        "To get a better intuitive understanding of what convolution is, we are going to look at a 1D example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaUM9n9a6Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolution comes from signal processing\n",
        "# We will look at a simple one-dimensional signal\n",
        "# As a demonstration, this is how you would define a sine wave\n",
        "\n",
        "lim = 8 * np.pi\n",
        "x_axis = np.linspace(-lim, lim, 200)\n",
        "sin_x = np.sin(x_axis)\n",
        "\n",
        "plt.plot(x_axis, sin_x, label=\"sin(x)\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1nKyr1JCmxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a special signal that has some interesting event which we will train a model to recognize\n",
        "# Analogous to \"Hey Siri\" or \"Ok, Google\"\n",
        "\n",
        "def special_signal():\n",
        "    low = -12 * np.pi\n",
        "    high = 4 * np.pi\n",
        "    \n",
        "    space_s = np.linspace(2 * low, 2 * high, 210)\n",
        "    space = np.linspace(-8 * np.pi, 8 * np.pi, 210)\n",
        "    \n",
        "    noise = np.random.randn(space.size) * 0.03\n",
        "    \n",
        "    event = np.sin(space_s) / space_s\n",
        "    \n",
        "    base_signal = np.sin(space) * noise\n",
        "    \n",
        "    return base_signal + event\n",
        "    \n",
        "ss = special_signal()\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.vlines([140, 171], -0, 1, linestyles=\"--\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MokEwbFxEmRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = np.zeros_like(ss)\n",
        "label[140:171] = 1.0\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctXbtgpfLOuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define convolution from scratch\n",
        "\n",
        "def convolve(signal, kernel, stride=1):\n",
        "    # Establish starting shapes\n",
        "    signal_width = signal.shape[0]\n",
        "    kernel_width = kernel.shape[0]\n",
        "    \n",
        "    # Use shapes to get ratios\n",
        "    number_of_positions = signal_width // stride\n",
        "\n",
        "    # Define empty collections to save results\n",
        "    out = []\n",
        "    input_slices = []\n",
        "    \n",
        "    for i in range(number_of_positions):\n",
        "        # Start at some point in the signal we are searching\n",
        "        start_index = i * stride\n",
        "        \n",
        "        # Take a subset of that signal\n",
        "        this_slice = signal[start_index:start_index + kernel_width]\n",
        "        \n",
        "        # More shape management\n",
        "        this_slice_width = this_slice.shape[0]\n",
        "        \n",
        "        # Ensure that our subset is the same shape as our kernel\n",
        "        this_slice = np.pad(this_slice, (0, kernel_width - this_slice_width), 'constant')\n",
        "        \n",
        "        # Save our input for later\n",
        "        input_slices.append(this_slice)\n",
        "        \n",
        "        # The main event of convolution!\n",
        "        \n",
        "        # Element-wise multiplication...\n",
        "        product = this_slice * kernel\n",
        "        \n",
        "        # ...and a sum of all of the results\n",
        "        summation = np.sum(product)\n",
        "        out.append(summation)\n",
        "\n",
        "    # Return the result and the input (we will want that later)\n",
        "    return np.array(out), np.stack(input_slices)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TUUtAVnQz__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Examine one step of applying convolution\n",
        "\n",
        "# Fill a kernel with random numbers\n",
        "kernel = np.random.randn(30)\n",
        "\n",
        "# Do the thing\n",
        "output, input_slices = convolve(ss, kernel, stride=1)\n",
        "\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(output, label=\"output\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB-P8NCZTqLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a metric to measure how far off we are\n",
        "\n",
        "def squared_error(output, target):\n",
        "    error = target - output\n",
        "    sq_error = (error ** 3) / np.abs(error)\n",
        "    return sq_error\n",
        "\n",
        "se = squared_error(output, label)\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(output, label=\"output\")\n",
        "plt.plot(se, label=\"error\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ6QIHU3UxJM",
        "colab_type": "text"
      },
      "source": [
        "## Things Required to Make Machines Learn\n",
        "\n",
        "1. Input\n",
        "2. Label\n",
        "\n",
        "(Dataset)\n",
        "\n",
        "3. Function to transform Input -> Label (Convolution)\n",
        "4. Function to measure how far off the output is from the label (Squared Error)\n",
        "\n",
        "(Model)\n",
        "\n",
        "5. A way to update kernel based on how far off the output is\n",
        "\n",
        "(Backpropagation, i.e. derivatives)\n",
        "\n",
        "$$ O(\\mathbf{I}) = \\mathbf{I} \\cdot \\mathbf{k} $$\n",
        "$$\\frac{\\delta O}{\\delta \\mathbf{k}} = \\mathbf{I} $$\n",
        "\n",
        "We can use this derivative to attribute how much the combination of our input and kernel contribute to our error\n",
        "\n",
        "When we know the magnitude of that contribution, we can use it to guide our kernel to better and better results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMTzBraRr_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply our convolution function to learn about the event in the special signal\n",
        "\n",
        "kernel = np.random.randn(30)\n",
        "learning_rate = 0.0005\n",
        "losses = []\n",
        "number_of_tries = 1000\n",
        "\n",
        "for try_number in range(number_of_tries):\n",
        "    # Use our convolution function\n",
        "    output, input_slices = convolve(ss, kernel)\n",
        "    \n",
        "    # Measure how far off we are\n",
        "    se = squared_error(output, label)\n",
        "    \n",
        "    # Average the error to produce a loss\n",
        "    loss = se.mean()\n",
        "    \n",
        "    # Save loss to track model progress\n",
        "    losses += [loss]\n",
        "    \n",
        "    # Print out our progress every 50th try\n",
        "    if try_number % 50 == 0:\n",
        "        print(\"Mean Squared Error Loss: {:.4f}\".format(loss))\n",
        "    \n",
        "    # Manual backpropagation\n",
        "    for (error, in_slice) in zip(se, input_slices):\n",
        "        \n",
        "        # Use error, input signal, and learning rate to attribute\n",
        "        # an update amount to each element of our kernel\n",
        "        \n",
        "        kernel_update = error * in_slice * learning_rate\n",
        "        \n",
        "        # Apply the update to our kernel to shift it closer next time\n",
        "        \n",
        "        kernel = kernel + kernel_update\n",
        "\n",
        "# Save losses for plotting\n",
        "losses = np.array(losses)       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzTInm_paKcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot trained output and label\n",
        "\n",
        "ssr = ss\n",
        "\n",
        "output_r, _ = convolve(ssr, kernel)\n",
        "\n",
        "plt.plot(ssr, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(output_r, label=\"output\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNE5T9TL-0-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Smooth and plot\n",
        "\n",
        "def gaussian_kernel(mu=0, sigma=1, width=30):\n",
        "    x = np.linspace(-sigma, 2 * sigma, width)\n",
        "    y = np.linspace(-sigma, 2 * sigma, width)\n",
        "    exp = np.e ** (-1 * (x - mu) ** 2)/(2 * sigma ** 2)\n",
        "    \n",
        "    return (1 / (sigma * np.sqrt(2 * np.pi))) * exp\n",
        "\n",
        "smooth, _ = convolve(output, gaussian_kernel())\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(smooth / smooth.max(), label=\"smoothed output\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# We can interpret this as \"I am 100% confident that the event that I am trained for starts at x = 140\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_n_lxyEaa9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot and print kernel\n",
        "\n",
        "print(kernel)\n",
        "plt.plot(kernel, label=\"kernel\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFbrSE0DlUdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot loss over time\n",
        "\n",
        "plt.plot(losses, label=\"loss over time\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAnUB2HdrAEr",
        "colab_type": "text"
      },
      "source": [
        "# How does it work (Summary)\n",
        "\n",
        "Neural networks use (fairly) simple mathematical functions to discover non-obvious solutions.\n",
        "These are not found by describing complex rules, but merely by describing relationships between inputs and desired outputs.\n",
        "\n",
        "We can use ideas from calculus and linear algebra to start from random values that transform from input to output and steer the output towards better and better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP4xuiI69jaB",
        "colab_type": "text"
      },
      "source": [
        "# Applications\n",
        "\n",
        "## Generative Models\n",
        "\n",
        "One of the fascinating things about deep neural nets is that they can learn arbitrary, _qualitative_ functions.\n",
        "\n",
        "Functions like \"generate images that are similar to this collection of images\".\n",
        "\n",
        "And this can be done with operations similar to what we have just written."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a8LXGbmR8mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download directory of images for dataset\n",
        "# Directory should have at least one subdirectory that contains all images\n",
        "# i.e. /ALotOfPlansModified/all/plan_1.jpg, ...plan_2.jpg, ...good_building_plan.jpg, etc.\n",
        "\n",
        "!wget https://www.dropbox.com/sh/v7uu10rkve2vnt8/AAA6InT1OjUquORG0i1syD7ka?dl=0 -O ALotOfPlans.zip > /dev/null\n",
        "!unzip ALotOfPlans.zip -d . > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB09p9bl3W7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download AEGeAN module\n",
        "!curl https://raw.githubusercontent.com/TEECOM/this-building-does-not-exist/spaceheater-training/ml/python/AEGeAN.py --output AEGeAN.py > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mv0Al6fK8uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download pretrained weights files\n",
        "\n",
        "!wget https://www.dropbox.com/s/rr9xvcijs5k4mxb/1561579878-discriminator.pth?dl=0 -O discriminator.pth > /dev/null\n",
        "!wget https://www.dropbox.com/s/5fn9jiaulsxz9fx/1561579878-generator.pth?dl=0 -O generator.pth > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbC1kLPM_HKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import a generative network framework for generating architectural drawings\n",
        "\n",
        "from AEGeAN import AEGeAN, Generator, Discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJR2e3HT_u4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the core function of the AEGeAN generative network\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.ConvTranspose2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            bias=False\n",
        "            )\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv(x)\n",
        "        y = self.bn(y)\n",
        "\n",
        "        return nnf.leaky_relu(y, negative_slope=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULchKdC5E6qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a generator network using our custom ConvBlock\n",
        "G = Generator.Generator(ConvBlock, feature_coeff=4, out_channels=1)\n",
        "\n",
        "# Create a discriminator to use with our generator\n",
        "D = Discriminator.Discriminator(Discriminator.ConvBlock, feature_coeff=4, in_channels=1)\n",
        "\n",
        "# Load pretrained weights to start our network in a favorable state\n",
        "\n",
        "state_dictionaries = {\n",
        "    \"generator\": torch.load(\"generator.pth\"),\n",
        "    \"discriminator\": torch.load(\"discriminator.pth\")\n",
        "}\n",
        "\n",
        "\n",
        "G.load_state_dict(state_dictionaries[\"generator\"])\n",
        "D.load_state_dict(state_dictionaries[\"discriminator\"])\n",
        "\n",
        "G.cuda()\n",
        "D.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Jp8lN9U_r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn the downloaded directory of images into a dataset\n",
        "\n",
        "dataloader, n_batches = AEGeAN.image_dataset(\"alotofplansmodified\", batch_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOAZmQRScerk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for turning tensors into drawings\n",
        "to_image = transforms.ToPILImage()\n",
        "\n",
        "# Number of trips through the dataset\n",
        "n_epochs = 100\n",
        "\n",
        "# Learning rate\n",
        "lr = 5e-4\n",
        "\n",
        "ae_criterion = nn.BCELoss(reduction=\"mean\").cuda()\n",
        "d_criterion = nn.BCELoss(reduction=\"mean\").cuda()\n",
        "\n",
        "for epoch_num in range(n_epochs):\n",
        "    \n",
        "    # Create optimizers to adjust the parameters of each model\n",
        "    g_optim = optim.Adam(G.parameters(), lr=lr)\n",
        "    d_optim = optim.SGD(D.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    for batch_num, (data, label) in enumerate(dataloader):\n",
        "\n",
        "        # Shape management\n",
        "        batch_size, channels, height, width = data.shape\n",
        "\n",
        "        # Create label for real images\n",
        "        real_label = torch.zeros(batch_size, 2, 1, 1).cuda()\n",
        "        real_label[:, 0, :, :] = 1.0\n",
        "        \n",
        "        # Create label for fake images\n",
        "        fake_label = torch.zeros(batch_size, 2, 1, 1).cuda()\n",
        "        fake_label[:, 1, :, :] = 1.0\n",
        "\n",
        "        # Move real images to GPU\n",
        "        data = data.cuda()\n",
        "\n",
        "        data.requires_grad = True\n",
        "        \n",
        "        #--------------\n",
        "        # Autoencoder\n",
        "        #--------------\n",
        "\n",
        "        # Encode real images into small vector\n",
        "        encoded = D(data, mode=\"ae\")\n",
        "        e_mu = encoded.mean().detach()\n",
        "        e_std = encoded.std().detach()\n",
        "        \n",
        "        # Upsample encoded vector back to images\n",
        "        decoded = G(encoded, mode=\"ae\")\n",
        "\n",
        "        # Measure how far off we are from recreating the original\n",
        "        reconstruction_loss = ae_criterion(decoded, data.detach())\n",
        "\n",
        "        reconstruction_loss.backward()\n",
        "\n",
        "        g_optim.step()\n",
        "        d_optim.step()\n",
        "\n",
        "        g_optim.zero_grad()\n",
        "        d_optim.zero_grad()\n",
        "\n",
        "        #--------------\n",
        "        # Generative Adversarial Network\n",
        "        #--------------\n",
        "\n",
        "        # Train discriminator on real images\n",
        "        classify_real = D(data, mode=\"discriminator\")\n",
        "\n",
        "        real_loss = d_criterion(classify_real, real_label)\n",
        "\n",
        "        z = torch.randn(batch_size, 128, 1, 1).cuda()\n",
        "        z.requires_grad = True\n",
        "\n",
        "        # Generate fake images\n",
        "        fake_images = G(z, mode=\"generator\", mu=e_mu, std=e_std)\n",
        "\n",
        "        # Train discriminator on fake images\n",
        "        classify_fake = D(fake_images.detach(), mode=\"discriminator\")\n",
        "\n",
        "        fake_loss = d_criterion(classify_fake, fake_label)\n",
        "\n",
        "        # Measure total (real & fake classification) performance of discriminator\n",
        "        d_total_loss = real_loss + fake_loss\n",
        "        d_total_loss.backward()\n",
        "\n",
        "        d_optim.step()\n",
        "        d_optim.zero_grad()\n",
        "\n",
        "        # Measure how well the generator fooled the discriminator\n",
        "        classify_generator = D(fake_images, mode=\"discriminator\")\n",
        "\n",
        "        fooled_loss = d_criterion(classify_generator, real_label)\n",
        "\n",
        "        fooled_loss.backward()\n",
        "\n",
        "        g_optim.step()\n",
        "        g_optim.zero_grad()\n",
        "        \n",
        "        # Printing & logging\n",
        "        now = math.floor(time.time())\n",
        "\n",
        "        if batch_num % 20 == 0:\n",
        "\n",
        "            msg =\\\n",
        "                \"Epoch [{:4d}/{:4d}] Batch [{:4d}/{:4d}]\\n\"+\\\n",
        "                \"Encoded: [Mu: {:.4f} Sd: {:.4f}]\\n\"+\\\n",
        "                \"Losses [AE: {:.4f} Real: {:.4f} Fake: {:.4f} Generator: {:.4f}]\"\n",
        "\n",
        "            msg = msg.format(\n",
        "                epoch_num,\n",
        "                n_epochs,\n",
        "                batch_num,\n",
        "                n_batches,\n",
        "                e_mu.item(),\n",
        "                e_std.item(),\n",
        "                reconstruction_loss.item(),\n",
        "                real_loss.item(),\n",
        "                fake_loss.item(),\n",
        "                fooled_loss.item()\n",
        "            )\n",
        "\n",
        "            print(msg)\n",
        "\n",
        "\n",
        "            nrow = int(math.sqrt(batch_size))\n",
        "            \n",
        "            decoded_grid = vutils.make_grid(decoded.clone().cpu(), nrow=nrow, normalize=True)\n",
        "            fake_grid = vutils.make_grid(fake_images.clone().cpu(), nrow=nrow, normalize=True)\n",
        "            \n",
        "            plt.imshow(to_image(decoded_grid))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            \n",
        "            plt.imshow(to_image(fake_grid))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5rOKPqkWgFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate single image\n",
        "\n",
        "n_images = 1\n",
        "\n",
        "z = torch.randn(n_images, 128, 1, 1).cuda()\n",
        "\n",
        "output = G(z, mode=\"generator\", mu=e_mu, std=e_std)\n",
        "\n",
        "grid = vutils.make_grid(output.detach().cpu(), nrow=int(math.sqrt(n_images)), normalize=True)\n",
        "\n",
        "to_image(grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_sVtOVEz9xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_dot(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwM3t-9t4rvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhrctd5cBAI2",
        "colab_type": "text"
      },
      "source": [
        "# Applications (Summary)\n",
        "\n",
        "## Just the beginning\n",
        "\n",
        "Even with a small amount of data (~100 datapoints), freely available compute power, and a simple neural network, we can begin to train a machine to generate architectural features purely from pixel values, with no _a priori_ knowledge of walls, rooms, stairs, etc.\n",
        "\n",
        "Clearly, this is not a product that is ready for commercial use, but a sketch of what could be coming next.\n",
        "\n",
        "## Join the conversation\n",
        "\n",
        "If you are interested in more, you should check out [Architecture ex Machina](https://www.aem.ai)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSxkf3YmBCiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}