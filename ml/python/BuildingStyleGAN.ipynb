{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as odict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Add:\n",
    "\n",
    "Sequences of stuff (list comprehensions)\n",
    "\n",
    "Tensor intro\n",
    "\n",
    "Drawing with tensors\n",
    "\n",
    "Math = Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences\n",
    "\n",
    "## Expansion and Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors are Drawings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math is Drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    LatentDimension = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Network\n",
    "\n",
    "The mapping network is stated to be a nonlinear function:\n",
    "\n",
    "$$f : Z \\rightarrow W$$\n",
    "\n",
    "The authors state that this function is implemented practically as a multilayer perceptron (MLP) with 8 layers and that both spaces $Z$ and $W$ are set to be 512-dimensional.\n",
    "\n",
    "We could state this more explicitly as:\n",
    "\n",
    "$$ Z, W \\in \\mathbb{R}^{512} $$\n",
    "\n",
    "All that this means is that both $Z$ and $W$ are vectors of real numbers that have 512 entries ( `[1.1, 2.65, 3.141, ..., 6.022]` ).\n",
    "\n",
    "### Multilayer Perceptron\n",
    "\n",
    "But what, exactly, is a \"multilayer perceptron\"?\n",
    "\n",
    "An MLP is a very simple kind of neural network that simply takes a vector input, multiplies it with a weight matrix to get another vector, and then repeats for some number of layers. Formally:\n",
    "\n",
    "$$ x \\in \\mathbb{R}^{1 \\times m} $$\n",
    "$$ w \\in \\mathbb{R}^{m \\times n} $$\n",
    "$$ y \\in \\mathbb{R}^{1 \\times n} $$\n",
    "\n",
    "This is essentially just a vector, matrix product. If $m \\gt n$ then the layer will be performing data reduction, if $m \\lt n$ then it will be performing data expansion. Notably, if the weight matrix $w$ is square, $x$ and $y$ will be the same dimension, and this is what is happening in the Mapping Network. There is also no mention of a nonlinearity applied to the Mapping Network in the paper, so our construction in code is very straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Sequential):\n",
    "    def __init__(self, layer_count=8, latent_dim=512):\n",
    "        super(MappingNetwork, self).__init__()\n",
    "\n",
    "        for layer_number in range(layer_count):\n",
    "            layer_name = \"linear_{}\".format(layer_number)\n",
    "            layer = nn.Linear(latent_dim, latent_dim)\n",
    "            self.add_module(layer_name, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Note\n",
    "\n",
    "$$ f \\sim mn $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MappingNetwork(\n",
       "  (linear_0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_5): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (linear_7): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn = MappingNetwork()\n",
    "mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis Network\n",
    "\n",
    "The authors' diagram of the Synthesis Network shows a repeating block of upsample, convolution, noise scaling/addition, and a function that they define called `AdaIN`.\n",
    "$$ W \\in \\mathbb{R}^n $$\n",
    "$$ Y \\in \\mathbb{R}^{2n} $$\n",
    "$$ A : W \\rightarrow Y $$\n",
    "\n",
    "$Y$ can be thought of as a style space where the scalar components are parameters that control both how strongly feature maps in $x$ are carried forward, and how much it is shifted around the style space.\n",
    "\n",
    "$$ AdaIN(x_i, y) = y_{s, i}\\frac{x_i - \\mu(x_i)}{\\sigma(x_i)} + y_{b, i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(A, self).__init__()\n",
    "        self.affine = nn.Linear(in_features, 2 * in_features)\n",
    "    \n",
    "    def forward(self, w):\n",
    "        return self.affine(w).reshape(2, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(nn.Module):\n",
    "    def __init__(self, height, width, num_features):\n",
    "        super(B, self).__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.noise_image = torch.randn(1, 1, height, width)\n",
    "        \n",
    "        self.scaling_factors = torch.nn.Parameter(data=torch.randn(1, num_features, 1, 1), requires_grad=True)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.scaling_factors.expand(1, -1, self.height, self.width) * self.noise_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdaIN, self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        mu_x    = x.mean(dim=(0, 2, 3)).reshape(1, -1, 1, 1)\n",
    "        sigma_x = x.std(dim=(0, 2, 3)).reshape(1, -1, 1, 1)\n",
    "        \n",
    "        normed_x = (x - mu_x) / sigma_x\n",
    "        \n",
    "        y = y.reshape(2, -1, 1, 1)\n",
    "        \n",
    "        return (y[0, :] * x) + y[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        mu_x = x.mean(dim=(1)).reshape(n, 1, h, w)\n",
    "        sigma_x = x.std(dim=(1)).reshape(n, 1, h, w)\n",
    "        \n",
    "        normed_x = (x - mu_x) / sigma_x\n",
    "        \n",
    "        return normed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, (3, 3), 1, 1)\n",
    "        self.conv.weight.data.normal_(0, 1)\n",
    "        self.conv.bias.data.fill_(0)\n",
    "        \n",
    "        self.norm = PixelNorm()\n",
    "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, height, width):\n",
    "        super(SynthesisBlock, self).__init__()\n",
    "        \n",
    "        self.upsample = nn.UpsamplingBilinear2d((height, width))\n",
    "        self.conv0 =    ConvBlock(in_channels, out_channels)\n",
    "        self.b0 =       B(height, width, out_channels)\n",
    "        self.a0 =       A(out_channels)\n",
    "        self.adain0 =   AdaIN()\n",
    "        \n",
    "        self.conv1 =    ConvBlock(out_channels, out_channels)\n",
    "        self.b1 =       B(height, width, out_channels)\n",
    "        self.a1 =       A(out_channels)\n",
    "        self.adain1 =   AdaIN()\n",
    "    \n",
    "    def forward(self, x, w):\n",
    "\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.conv0(x)\n",
    "        x = x + self.b0()\n",
    "        y = self.a0(w)\n",
    "        x = self.adain0(x, y)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = x + self.b1()\n",
    "        y = self.a1(w)\n",
    "        x = self.adain1(x, y)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = SynthesisBlock(512, 512, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynthesisBlock(\n",
       "  (upsample): UpsamplingBilinear2d(size=(4, 4), mode=bilinear)\n",
       "  (conv0): ConvBlock(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm): PixelNorm()\n",
       "    (act): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (b0): B()\n",
       "  (a0): A(\n",
       "    (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  )\n",
       "  (adain0): AdaIN()\n",
       "  (conv1): ConvBlock(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm): PixelNorm()\n",
       "    (act): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (b1): B()\n",
       "  (a1): A(\n",
       "    (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  )\n",
       "  (adain1): AdaIN()\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1255, -1.2977,  0.2635,  0.0455],\n",
       "          [-0.1651, -0.8773,  0.1759, -0.5719],\n",
       "          [-0.1444, -0.6601,  0.7944, -1.1124],\n",
       "          [-0.1543, -0.7806, -0.0418,  0.2998]],\n",
       "\n",
       "         [[ 1.1772,  1.6378,  0.7707,  0.7288],\n",
       "          [ 1.0830,  0.8333,  0.7415,  0.6426],\n",
       "          [ 0.8833,  0.8149,  0.6699,  0.9392],\n",
       "          [ 0.8603,  1.0329,  0.8100,  0.5590]],\n",
       "\n",
       "         [[-0.4264, -0.4274, -0.3183, -0.3637],\n",
       "          [-0.3772, -0.4237, -0.3478, -0.3866],\n",
       "          [-0.4241, -0.4003, -0.3102, -0.4323],\n",
       "          [-0.3712, -0.3859, -0.3717, -0.4046]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.8680,  0.8238,  0.6649,  0.7425],\n",
       "          [ 0.7565,  0.7942,  0.7109,  0.7464],\n",
       "          [ 0.7294,  0.7699,  0.6533,  0.8193],\n",
       "          [ 0.7353,  0.7739,  0.7147,  0.7038]],\n",
       "\n",
       "         [[-0.0559,  0.0491,  0.5194,  0.4267],\n",
       "          [ 0.4789,  0.4356,  0.8297,  0.2365],\n",
       "          [ 0.0794,  0.5509,  0.2798,  0.2563],\n",
       "          [ 0.6123,  0.9285,  0.8353,  0.9614]],\n",
       "\n",
       "         [[-0.3897, -0.3898, -0.3915, -0.3917],\n",
       "          [-0.3910, -0.3902, -0.3912, -0.3908],\n",
       "          [-0.3909, -0.3906, -0.3921, -0.3900],\n",
       "          [-0.3910, -0.3904, -0.3912, -0.3911]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 512, 4, 4)\n",
    "w = torch.randn(1, 512)\n",
    "sb(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
