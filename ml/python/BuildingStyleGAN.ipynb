{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as odict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Add:\n",
    "\n",
    "Sequences of stuff (list comprehensions)\n",
    "\n",
    "Tensor intro\n",
    "\n",
    "Drawing with tensors\n",
    "\n",
    "Math = Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences\n",
    "\n",
    "## Expansion and Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors are Drawings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math is Drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    LatentDimension = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Network\n",
    "\n",
    "The mapping network is stated to be a nonlinear function:\n",
    "\n",
    "$$f : Z \\rightarrow W$$\n",
    "\n",
    "The authors state that this function is implemented practically as a multilayer perceptron (MLP) with 8 layers and that both spaces $Z$ and $W$ are set to be 512-dimensional.\n",
    "\n",
    "We could state this more explicitly as:\n",
    "\n",
    "$$ Z, W \\in \\mathbb{R}^{512} $$\n",
    "\n",
    "All that this means is that both $Z$ and $W$ are vectors of real numbers that have 512 entries ( `[1.1, 2.65, 3.141, ..., 6.022]` ).\n",
    "\n",
    "### Multilayer Perceptron\n",
    "\n",
    "But what, exactly, is a \"multilayer perceptron\"?\n",
    "\n",
    "An MLP is a very simple kind of neural network that simply takes a vector input, multiplies it with a weight matrix to get another vector, and then repeats for some number of layers. Formally:\n",
    "\n",
    "$$ x \\in \\mathbb{R}^{1 \\times m} $$\n",
    "$$ w \\in \\mathbb{R}^{m \\times n} $$\n",
    "$$ y \\in \\mathbb{R}^{1 \\times n} $$\n",
    "\n",
    "This is essentially just a vector, matrix product. If $m \\gt n$ then the layer will be performing data reduction, if $m \\lt n$ then it will be performing data expansion. Notably, if the weight matrix $w$ is square, $x$ and $y$ will be the same dimension, and this is what is happening in the Mapping Network. There is also no mention of a nonlinearity applied to the Mapping Network in the paper, so our construction in code is very straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Sequential):\n",
    "    def __init__(self, layer_count=8, latent_dim=512):\n",
    "        super(MappingNetwork, self).__init__()\n",
    "\n",
    "        for layer_number in range(layer_count):\n",
    "            layer_name = \"linear_{}\".format(layer_number)\n",
    "            layer = nn.Linear(latent_dim, latent_dim)\n",
    "            self.add_module(layer_name, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Note\n",
    "\n",
    "$$ f \\sim mn $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis Network\n",
    "\n",
    "The authors' diagram of the Synthesis Network shows a repeating block of upsample, convolution, noise scaling/addition, and a function that they define called `AdaIN`.\n",
    "$$ W \\in \\mathbb{R}^n $$\n",
    "$$ Y \\in \\mathbb{R}^{2n} $$\n",
    "$$ A : W \\rightarrow Y $$\n",
    "\n",
    "$Y$ can be thought of as a style space where the scalar components are parameters that control both how strongly feature maps in $x$ are carried forward, and how much it is shifted around the style space.\n",
    "\n",
    "$$ AdaIN(x_i, y) = y_{s, i}\\frac{x_i - \\mu(x_i)}{\\sigma(x_i)} + y_{b, i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(nn.Module):\n",
    "    def __init__(self, in_features, w_dim=512):\n",
    "        super(A, self).__init__()\n",
    "        self.affine = nn.Linear(w_dim, 2 * in_features)\n",
    "    \n",
    "    def forward(self, w):\n",
    "        return self.affine(w).reshape(2, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(nn.Module):\n",
    "    def __init__(self, height, width, num_features):\n",
    "        super(B, self).__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.noise_image = torch.randn(1, 1, height, width)\n",
    "        \n",
    "        self.scaling_factors = torch.nn.Parameter(data=torch.randn(1, num_features, 1, 1), requires_grad=True)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.scaling_factors.expand(1, -1, self.height, self.width) * self.noise_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdaIN, self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        mu_x    = x.mean(dim=(0, 2, 3)).reshape(1, -1, 1, 1)\n",
    "        sigma_x = x.std(dim=(0, 2, 3)).reshape(1, -1, 1, 1)\n",
    "        \n",
    "        normed_x = (x - mu_x) / sigma_x\n",
    "        \n",
    "        y = y.reshape(2, -1, 1, 1)\n",
    "        \n",
    "        return (y[0, :] * x) + y[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PixelNorm\n",
    "From the [Progressive Growing of GANs paper](https://arxiv.org/pdf/1710.10196.pdf), section 4.2, the authors detail the per-pixel normalization function as:\n",
    "\n",
    "$$ b_{x, y} = \\frac{a_{x, y}}{\\sqrt{\\frac{1}{n}\\Sigma_{j=0}^{n-1}{(a^{j}_{x, y})^2 + \\epsilon}}} $$\n",
    "\n",
    "where $\\epsilon = 10^{-8}$ and $n$ is the number of feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 10 ** -8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        d = x.pow(2)\n",
    "        d = d.sum(dim=(1)) + self.epsilon\n",
    "        # substitute c for n to follow pytorch documentation (n, c, h, w)\n",
    "        d = d.mul(1 / c)\n",
    "        d = d.sqrt()\n",
    "        d = d.unsqueeze(1)\n",
    "\n",
    "        return x / d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, (3, 3), 1, 1)\n",
    "        self.conv.weight.data.normal_(0, 1)\n",
    "        self.conv.bias.data.fill_(0)\n",
    "        \n",
    "        self.norm = PixelNorm()\n",
    "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, height, width, w_dim=512):\n",
    "        super(SynthesisBlock, self).__init__()\n",
    "        \n",
    "        self.upsample = nn.UpsamplingBilinear2d((height, width))\n",
    "        self.conv0 =    ConvBlock(in_channels, out_channels)\n",
    "        self.b0 =       B(height, width, out_channels)\n",
    "        self.a0 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain0 =   AdaIN()\n",
    "        \n",
    "        self.conv1 =    ConvBlock(out_channels, out_channels)\n",
    "        self.b1 =       B(height, width, out_channels)\n",
    "        self.a1 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain1 =   AdaIN()\n",
    "    \n",
    "    def forward(self, tensor_dict):\n",
    "\n",
    "        x = tensor_dict[\"x\"]\n",
    "        w = tensor_dict[\"w\"]\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.conv0(x)\n",
    "        x = x + self.b0()\n",
    "        y = self.a0(w)\n",
    "        x = self.adain0(x, y)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = x + self.b1()\n",
    "        y = self.a1(w)\n",
    "        x = self.adain1(x, y)\n",
    "        \n",
    "        return {\"x\": x, \"w\": w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, height, width, w_dim=512):\n",
    "        super(InputBlock, self).__init__()\n",
    "        \n",
    "        self.conv0 =    ConvBlock(in_channels, out_channels)\n",
    "        self.b0 =       B(height, width, out_channels)\n",
    "        self.a0 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain0 =   AdaIN()\n",
    "        \n",
    "        self.b1 =       B(height, width, out_channels)\n",
    "        self.a1 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain1 =   AdaIN()\n",
    "    \n",
    "    def forward(self, tensor_dict):\n",
    "\n",
    "        x = tensor_dict[\"x\"]\n",
    "        w = tensor_dict[\"w\"]\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "        x = x + self.b0()\n",
    "        y = self.a0(w)\n",
    "        x = self.adain0(x, y)\n",
    "\n",
    "        x = x + self.b1()\n",
    "        y = self.a1(w)\n",
    "        x = self.adain1(x, y)\n",
    "        \n",
    "        return {\"x\": x, \"w\": w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(OutputBlock, self).__init__()\n",
    "        \n",
    "        self.to_rgb = nn.Conv2d(input_channels, 3, (1, 1))\n",
    "    \n",
    "    def forward(self, tensor_dict):\n",
    "        x = tensor_dict[\"x\"]\n",
    "        w = tensor_dict[\"w\"]\n",
    "        \n",
    "        x = self.to_rgb(x)\n",
    "        \n",
    "        return {\"x\": x, \"w\": w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGenerator(nn.Module):\n",
    "    def __init__(self, input_layer=None, layer_params=None, w_dim=512):\n",
    "        super(StyleGenerator, self).__init__()\n",
    "        \n",
    "        if input_layer == None:\n",
    "            input_layer = InputBlock(512, 512, 4, 4, w_dim=w_dim)\n",
    "        \n",
    "        self.input = input_layer\n",
    "\n",
    "        self.main = nn.Sequential()\n",
    "\n",
    "        if layer_params == None:\n",
    "            layer_params = [\n",
    "                (512, 512,    8,    8, w_dim),\n",
    "                (512, 512,   16,   16, w_dim),\n",
    "                (512, 512,   32,   32, w_dim),\n",
    "                (512, 256,   64,   64, w_dim),\n",
    "                (256, 128,  128,  128, w_dim),\n",
    "                (128,  64,  256,  256, w_dim),\n",
    "                ( 64,  32,  512,  512, w_dim),\n",
    "                ( 32,  16, 1024, 1024, w_dim),\n",
    "            ]\n",
    "        \n",
    "        self.layer_params = layer_params\n",
    "        \n",
    "        self.main_layer_count = len(self.layer_params)\n",
    "\n",
    "    def step_training_progression(self):\n",
    "        for child in self.main.children():\n",
    "            for p in child.parameters():\n",
    "                p.requires_grad = False\n",
    "                # Check that Progressive Growing of GANs actually freezes layers\n",
    "        \n",
    "        current_layer_count = len(list(self.main.children()))\n",
    "        \n",
    "        if len(self.layer_params) == 0:\n",
    "            return\n",
    "        \n",
    "        new_layer_params = self.layer_params.pop(0)\n",
    "        \n",
    "        final_out_channels = new_layer_params[1]\n",
    "        \n",
    "        self.main.add_module(\"sb{}\".format(current_layer_count), SynthesisBlock(*new_layer_params))\n",
    "        print(\"Added block with params:{}\\n\".format(new_layer_params))\n",
    "        \n",
    "        self.output = OutputBlock(final_out_channels)\n",
    "\n",
    "    def forward(self, tensor_dict):\n",
    "        tensor_dict = self.input(tensor_dict)\n",
    "        tensor_dict = self.main(tensor_dict)\n",
    "\n",
    "        return self.output(tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MappingNetwork()\n",
    "sg = StyleGenerator()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(mn)\n",
    "print(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.step_training_progression()\n",
    "sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 512, 4, 4, requires_grad=True)\n",
    "z = torch.randn(1, 512, requires_grad=True)\n",
    "\n",
    "w = mn(z)\n",
    "\n",
    "\n",
    "tensor_dict = {\"x\": x, \"w\": w}\n",
    "\n",
    "output = sg(tensor_dict)\n",
    "\n",
    "loss = criterion(torch.ones_like(output[\"x\"]), output[\"x\"])\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Sequential):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "    \n",
    "        layers = [\n",
    "            (\"conv0\",      nn.Conv2d(in_channels, out_channels, (3, 3), 1, 1)),\n",
    "            (\"act0\",       nn.LeakyReLU(negative_slope=0.2)),\n",
    "            (\"conv1\",      nn.Conv2d(out_channels, out_channels, (3, 3), 1, 1)),\n",
    "            (\"act1\",       nn.LeakyReLU(negative_slope=0.2)),\n",
    "            (\"downsample\", nn.AvgPool2d((2, 2)))\n",
    "        ]\n",
    "        \n",
    "        [self.add_module(n, l) for n, l in layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FadeInFromRGB(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_params=None):\n",
    "        super(StyleDiscriminator, self).__init__()\n",
    "\n",
    "        self.input = None\n",
    "\n",
    "        self.main = nn.Sequential()\n",
    "        \n",
    "        if layer_params == None:\n",
    "            layer_params = [\n",
    "                ( 32,  64),\n",
    "                ( 64, 128),\n",
    "                (128, 256),\n",
    "                (256, 512),\n",
    "                (512, 512),\n",
    "                (512, 512),\n",
    "                (512, 512),\n",
    "            ]\n",
    "        \n",
    "        self.layer_params = layer_params\n",
    "    \n",
    "    def step_training_progression(self):\n",
    "        for child in self.main.children():\n",
    "            for p in child.parameters():\n",
    "                p.requires_grad = False\n",
    "                # Check that Progressive Growing of GANs actually freezes layers\n",
    "        \n",
    "        current_layer_count = len(list(self.main.children()))\n",
    "        \n",
    "        if len(self.layer_params) == 0:\n",
    "            return\n",
    "        \n",
    "        new_layer_params = self.layer_params.pop(0)\n",
    "        \n",
    "        final_out_channels = new_layer_params[1]\n",
    "        \n",
    "        self.main.add_module(\"db{}\".format(current_layer_count), DiscriminatorBlock(*new_layer_params))\n",
    "        print(\"Added block with params:{}\\n\".format(new_layer_params))\n",
    "        \n",
    "        # self.output = OutputBlock(final_out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = StyleDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.step_training_progression()\n",
    "x = torch.randn(1, 32, 512, 512)\n",
    "\n",
    "y = sd(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = nn.Sequential()\n",
    "s1.add_module(\"linear0\", nn.Linear(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = nn.Sequential()\n",
    "s2.add_module(\"linear0\", s1.linear0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(s1.linear0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
