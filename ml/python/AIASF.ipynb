{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIASF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilW4XcCAaOTd",
        "colab_type": "text"
      },
      "source": [
        "# This Building Does Not Exist (Yet)\n",
        "\n",
        "## AIASF _NEXT_ 2019\n",
        "### Tyler Kvochick\n",
        "### TEECOM Research & Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf3BWrB0aoIt",
        "colab_type": "text"
      },
      "source": [
        "# Goals\n",
        "\n",
        "## Beyond Metaphors\n",
        "\n",
        "What is a neural network, literally?\n",
        "\n",
        "## Inner Workings\n",
        "\n",
        "What makes a neural network...work?\n",
        "\n",
        "## Applications\n",
        "\n",
        "What interesting models exist today and what can we make them do?\n",
        "\n",
        "(Hint: we can make sketchy floorplans)\n",
        "\n",
        "## Ultimately...\n",
        "\n",
        "To be unimpressed with machine learning jargon\n",
        "\n",
        "And to see machine learning as a practical tool rather than a mysterious buzzword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMg_xxxiqHrf",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "* All of this is happening in a remote Linux server\n",
        "* Under `Runtime` (above), select `Change Runtime Type` and set `Hardware Accelerator` to `GPU`\n",
        "* Use the demo cell to understand syntax & notebook environment\n",
        "* Install a network visualization module\n",
        "* Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z11hgKaNgwHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Demo cell!\n",
        "\n",
        "# Each light gray block (cell) can just be copied and pasted into the Colab notebook\n",
        "# Select the cell and hit Shift + Enter to execute it\n",
        "# The output for each cell will appear below it as it runs\n",
        "# When it is finished running, a number will appear in brackets at the far top left\n",
        "\n",
        "# The world's shortest Python tutorial:\n",
        "\n",
        "# Any text on a line after a `#` will be ignored as a code comment\n",
        "\n",
        "# Use `def` to define a reusable subroutine (function)\n",
        "def demo_function(name, number):\n",
        "    \n",
        "    # Assign values to identifiers with `=`\n",
        "    # Use double quotes `\"\"` to make a string\n",
        "    # Use `\"{}\".format(...some value...)` to put values into strings\n",
        "    message = \"Hello {}! Welcome to AIASF NEXT!\\n\".format(name)\n",
        "\n",
        "    # Do some math\n",
        "    x = 2\n",
        "    \n",
        "    # Raise two to the power that the user specifies with `number`\n",
        "    result = 2 ** number\n",
        "    \n",
        "    # Add that to our message\n",
        "    message += \"2 to the power of {} is {}\".format(number, result)\n",
        "    \n",
        "    # Print the message\n",
        "    print(message)\n",
        "    \n",
        "    # Give back the result of the math\n",
        "    return result\n",
        "\n",
        "# Use parentheses `()` after a function name to call it\n",
        "# Any arguments that it requires are put in order inside the parens\n",
        "some_power_of_two = demo_function(\"Tyler\", 8)\n",
        "\n",
        "# The last value in the cell will be appended to the output\n",
        "some_power_of_two\n",
        "\n",
        "# Congrats! You are now a Python programmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whokGTbb5z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Commands prefixed with `!` are sent to the runtime's terminal emulator\n",
        "# Use the system package manager to install a non-standard module and hide the output\n",
        "\n",
        "!pip install torchviz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Pb2DroWfWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import a lot of packages for interacting with the filesystem, doing math, working with images, and building neural networks\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchviz import make_dot\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Configure the interactive plot size\n",
        "matplotlib.rcParams[\"figure.figsize\"] = (8, 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er15aE3zZppp",
        "colab_type": "text"
      },
      "source": [
        "# Beyond Metaphors\n",
        "\n",
        "What does a neural network look like?\n",
        "\n",
        "These are just concepts, we will look at literal versions in section 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE-Fay4AZ0kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Demo class just to see multiple representations of a neural network\n",
        "\n",
        "class NetworkVisualization(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetworkVisualization, self).__init__()\n",
        "        \n",
        "        # Add 2 sets of layers \n",
        "        # Set 0\n",
        "        self.conv0 = nn.Conv2d(3, 6, (3, 3))\n",
        "        self.act0 = nn.LeakyReLU()\n",
        "        # Set 1\n",
        "        self.conv1 = nn.Conv2d(3, 6, (3, 3))\n",
        "        self.act1 = nn.LeakyReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Use both sets of layers\n",
        "        x0 = self.act0(self.conv0(x))\n",
        "        x1 = self.act1(self.conv1(x))\n",
        "        \n",
        "        # Sum the result\n",
        "        return x0 + x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhlxDfhCX3lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an instance of our class\n",
        "nv = NetworkVisualization().cuda()\n",
        "\n",
        "# Create a fake image made of white noise with the sizes: (1 batch, 3 channels (RGB), 512 pixels high, 512 pixels wide)\n",
        "# Shapes are very important in deep learning\n",
        "fake_image = torch.randn(1, 3, 512, 512).cuda()\n",
        "\n",
        "# Use the created instance\n",
        "out = nv(fake_image)\n",
        "\n",
        "# Examine how the neural network changed the shape of our input\n",
        "print(\"Output shape: {}\".format(out.shape))\n",
        "print(nv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvk58yp0YJNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Render the graph\n",
        "make_dot(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g6AhXApZmEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Render the parameters\n",
        "params = [p for p in list(nv.conv0.parameters())]\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "061DVh7-bSqg",
        "colab_type": "text"
      },
      "source": [
        "# No More Metaphors (Summary)\n",
        "\n",
        "## Multiple Representations of NNs\n",
        "\n",
        "1. As executable code / structured data (software)\n",
        "2. As a connective graph (visualization)\n",
        "3. As lists of numbers organized into rectilinear shapes (tensors)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfzLAltZneAz",
        "colab_type": "text"
      },
      "source": [
        "# Inner Workings\n",
        "\n",
        "We have seen that deep learning models are full of orthogonal collections of numbers that we call tensors. The rest of the model is made of mathematical functions for combining those tensors.\n",
        "\n",
        "## Convolution\n",
        "\n",
        "For working with images, the most common function for combining tensors in a learnable way is called convolution.\n",
        "\n",
        "Convolution is a confusing name for \"searching for known patterns\".\n",
        "\n",
        "To get a better intuitive understanding of what convolution is, we are going to look at a 1D example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AaUM9n9a6Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolution comes from signal processing\n",
        "# Look at a simple one-dimensional signal\n",
        "\n",
        "lim = 8 * np.pi\n",
        "x_axis = np.linspace(-lim, lim, 200)\n",
        "sin_x = np.sin(x_axis)\n",
        "\n",
        "plt.plot(x_axis, sin_x, label=\"sin(x)\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1nKyr1JCmxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a special signal that has some interesting event which we will train a model to recognize\n",
        "# Analogous to \"Hey Siri\" or \"Ok, Google\"\n",
        "\n",
        "def special_signal():\n",
        "    low = -12 * np.pi\n",
        "    high = 4 * np.pi\n",
        "    \n",
        "    space_s = np.linspace(2 * low, 2 * high, 210)\n",
        "    space = np.linspace(-8 * np.pi, 8 * np.pi, 210)\n",
        "    \n",
        "    noise = np.random.randn(space.size) * 0.03\n",
        "    \n",
        "    event = np.sin(space_s) / space_s\n",
        "    \n",
        "    base_signal = np.sin(space) * noise\n",
        "    \n",
        "    return base_signal + event\n",
        "    \n",
        "ss = special_signal()\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.vlines([140, 171], -0, 1, linestyles=\"--\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MokEwbFxEmRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = np.zeros_like(ss)\n",
        "label[140:171] = 1.0\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctXbtgpfLOuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define convolution from scratch\n",
        "\n",
        "def convolve(signal, kernel, stride=1):\n",
        "    # Establish starting shapes\n",
        "    signal_width = signal.shape[0]\n",
        "    kernel_width = kernel.shape[0]\n",
        "    \n",
        "    # Use shapes to get ratios\n",
        "    number_of_positions = signal_width // stride\n",
        "\n",
        "    # Define empty collections to save results\n",
        "    out = []\n",
        "    input_slices = []\n",
        "    \n",
        "    for i in range(number_of_positions):\n",
        "        # Start at some point in the signal we are searching\n",
        "        start_index = i * stride\n",
        "        \n",
        "        # Take a subset of that signal\n",
        "        this_slice = signal[start_index:start_index + kernel_width]\n",
        "        \n",
        "        # More shape management\n",
        "        this_slice_width = this_slice.shape[0]\n",
        "        \n",
        "        # Ensure that our subset is the same shape as our kernel\n",
        "        this_slice = np.pad(this_slice, (0, kernel_width - this_slice_width), 'constant')\n",
        "        \n",
        "        # Save our input for later\n",
        "        input_slices.append(this_slice)\n",
        "        \n",
        "        # The main event of convolution!\n",
        "        \n",
        "        # Element-wise multiplication...\n",
        "        product = this_slice * kernel\n",
        "        \n",
        "        # ...and a sum of all of the results\n",
        "        summation = np.sum(product)\n",
        "        out.append(summation)\n",
        "\n",
        "    # Return the result and the input (we will want that later)\n",
        "    return np.array(out), np.stack(input_slices)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TUUtAVnQz__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Examine one step of applying convolution\n",
        "\n",
        "# Fill a kernel with random numbers\n",
        "kernel = np.random.randn(30)\n",
        "\n",
        "# Do the thing\n",
        "output, input_slices = convolve(ss, kernel, stride=1)\n",
        "\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(output, label=\"output\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB-P8NCZTqLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a metric to measure how far off we are\n",
        "\n",
        "def squared_error(output, target):\n",
        "    error = target - output\n",
        "    sq_error = (error ** 3) / np.abs(error)\n",
        "    return sq_error\n",
        "\n",
        "se = squared_error(output, label)\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(output, label=\"output\")\n",
        "plt.plot(se, label=\"error\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ6QIHU3UxJM",
        "colab_type": "text"
      },
      "source": [
        "## Things Required to Make Machines Learn\n",
        "\n",
        "1. Input\n",
        "2. Label\n",
        "\n",
        "(Dataset)\n",
        "\n",
        "3. Function to transform Input -> Label (Convolution)\n",
        "4. Function to measure how far off the output is from the label (Squared Error)\n",
        "\n",
        "(Model)\n",
        "\n",
        "5. A way to update kernel based on how far off the output is\n",
        "\n",
        "(Backpropagation, i.e. derivatives)\n",
        "\n",
        "$$ O(\\mathbf{I}) = \\mathbf{I} \\cdot \\mathbf{k} $$\n",
        "$$\\frac{\\delta O}{\\delta \\mathbf{k}} = \\mathbf{I} $$\n",
        "\n",
        "We can use this derivative to attribute how much the combination of our input and kernel contribute to our error\n",
        "\n",
        "When we know the magnitude of that contribution, we can use it to guide our kernel to better and better results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMTzBraRr_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply our convolution function to learn about the event in the special signal\n",
        "\n",
        "kernel = np.random.randn(30)\n",
        "learning_rate = 0.0005\n",
        "losses = []\n",
        "number_of_tries = 1000\n",
        "\n",
        "for try_number in range(number_of_tries):\n",
        "    # Use our convolution function\n",
        "    output, input_slices = convolve(ss, kernel)\n",
        "    \n",
        "    # Measure how far off we are\n",
        "    se = squared_error(output, label)\n",
        "    \n",
        "    # Average the error to produce a loss\n",
        "    loss = se.mean()\n",
        "    \n",
        "    # Save loss to track model progress\n",
        "    losses += [loss]\n",
        "    \n",
        "    # Print out our progress every 50th try\n",
        "    if try_number % 50 == 0:\n",
        "        print(\"Mean Squared Error Loss: {:.4f}\".format(loss))\n",
        "    \n",
        "    # Manual backpropagation\n",
        "    for (error, in_slice) in zip(se, input_slices):\n",
        "        \n",
        "        # Use error, input signal, and learning rate to attribute\n",
        "        # an update amount to each element of our kernel\n",
        "        \n",
        "        kernel_update = error * in_slice * learning_rate\n",
        "        \n",
        "        # Apply the update to our kernel to shift it closer next time\n",
        "        \n",
        "        kernel = kernel + kernel_update\n",
        "\n",
        "# Save losses for plotting\n",
        "losses = np.array(losses)       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzTInm_paKcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot trained output and label\n",
        "\n",
        "ssr = ss\n",
        "\n",
        "output_r, _ = convolve(ssr, kernel)\n",
        "\n",
        "plt.plot(ssr, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(output_r, label=\"output\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNE5T9TL-0-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Smooth and plot\n",
        "\n",
        "def gaussian_kernel(mu=0, sigma=1, width=30):\n",
        "    x = np.linspace(-sigma, 2 * sigma, width)\n",
        "    y = np.linspace(-sigma, 2 * sigma, width)\n",
        "    exp = np.e ** (-1 * (x - mu) ** 2)/(2 * sigma ** 2)\n",
        "    \n",
        "    return (1 / (sigma * np.sqrt(2 * np.pi))) * exp\n",
        "\n",
        "smooth, _ = convolve(output, gaussian_kernel())\n",
        "\n",
        "plt.plot(ss, label=\"special signal\")\n",
        "plt.plot(label, label=\"label\")\n",
        "plt.plot(smooth / smooth.max(), label=\"smoothed output\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# We can interpret this as \"I am 100% confident that the event that I am trained for starts at x = 140\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_n_lxyEaa9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot and print kernel\n",
        "\n",
        "print(kernel)\n",
        "plt.plot(kernel, label=\"kernel\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFbrSE0DlUdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot loss over time\n",
        "\n",
        "plt.plot(losses, label=\"loss over time\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAnUB2HdrAEr",
        "colab_type": "text"
      },
      "source": [
        "# How does it work (Summary)\n",
        "\n",
        "Neural networks use (fairly) simple mathematical functions to discover non-obvious solutions.\n",
        "These are not found by describing complex rules, but merely by describing relationships between inputs and desired outputs.\n",
        "\n",
        "We can use ideas from calculus and linear algebra to start from random values that transform from input to output and steer the output towards better and better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP4xuiI69jaB",
        "colab_type": "text"
      },
      "source": [
        "# Applications\n",
        "\n",
        "## Generative Models\n",
        "\n",
        "One of the fascinating things about deep neural nets is that they can learn arbitrary, _qualitative_ functions.\n",
        "\n",
        "Functions like \"generate images that are similar to this collection of images\".\n",
        "\n",
        "And this can be done with operations similar to what we have just written."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a8LXGbmR8mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download directory of images for dataset\n",
        "# Directory should have at least one subdirectory that contains all images\n",
        "# i.e. /ALotOfPlansModified/all/plan_1.jpg, ...plan_2.jpg, ...good_building_plan.jpg, etc.\n",
        "\n",
        "!wget https://www.dropbox.com/sh/v7uu10rkve2vnt8/AAA6InT1OjUquORG0i1syD7ka?dl=0 -O ALotOfPlans.zip > /dev/null\n",
        "!unzip ALotOfPlans.zip -d . > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB09p9bl3W7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download DrawinGAN module\n",
        "!curl https://raw.githubusercontent.com/TEECOM/this-building-does-not-exist/spaceheater-training/ml/python/DrawinGAN.py --output DrawinGAN.py > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mv0Al6fK8uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download pretrained weights files\n",
        "\n",
        "!wget https://www.dropbox.com/s/mjd2ecya1wfi47z/1561511533-discriminator.pth?dl=0 -O discriminator.pth > /dev/null\n",
        "!wget https://www.dropbox.com/s/r5zz576fwjowqwx/1561511533-generator.pth?dl=0 -O generator.pth > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbC1kLPM_HKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import a generative network framework for generating architectural drawings\n",
        "\n",
        "from DrawinGAN import Generator, Discriminator, Container, Trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJR2e3HT_u4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the core function of the DrawinGAN generative network\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, latent_dim=512):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # The `a` function learns to transform the latent vector to a \"style\"\n",
        "        self.a = Generator.A(in_channels, latent_dim=latent_dim)\n",
        "\n",
        "        # Adaptive Instance Normalization uses the \"style\" to turn channels up or down\n",
        "        self.ada_in = Generator.AdaIN()\n",
        "\n",
        "        # Learn features that scale up our image\n",
        "        self.conv = nn.ConvTranspose2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=4,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "            )\n",
        "\n",
        "        # Normalize\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        # Apply gradient\n",
        "        self.act = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, container):\n",
        "        # Shape management\n",
        "        x_batches, x_channels, x_height, x_width = container.x.shape\n",
        "\n",
        "        # Take in our style vector and learn a transformation specific to this block\n",
        "        style = self.a(container.w)\n",
        "\n",
        "        # Reduce large variation in input and\n",
        "        # use our transformed style to control\n",
        "        # how much of the input moves forward\n",
        "        new_x = self.ada_in(container.x, style)\n",
        "\n",
        "        # Use our convolution layer to learn features that upsample to the target images\n",
        "        new_x = self.conv(new_x)\n",
        "        \n",
        "        # Normalize for variation introduced by convolution\n",
        "        new_x = self.bn(new_x)\n",
        "\n",
        "        # Apply a gradient for backpropagation\n",
        "        new_x = self.act(new_x)\n",
        "\n",
        "        return Container(new_x, container.w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULchKdC5E6qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a generator network using our custom ConvBlock\n",
        "generator = Generator.DrawingGenerator(ConvBlock, output_channels=1).cuda()\n",
        "\n",
        "# Create a discriminator to use with our generator\n",
        "discriminator = Discriminator.DrawingDiscriminator(input_channels=1).cuda()\n",
        "\n",
        "# Load pretrained weights to start our network in a favorable state\n",
        "\n",
        "state_dictionaries = {\n",
        "    \"generator\": torch.load(\"generator.pth\", map_location=\"cuda:0\"),\n",
        "    \"discriminator\": torch.load(\"discriminator.pth\", map_location=\"cuda:0\")\n",
        "}\n",
        "\n",
        "\n",
        "generator.load_state_dict(state_dictionaries[\"generator\"])\n",
        "discriminator.load_state_dict(state_dictionaries[\"discriminator\"])\n",
        "\n",
        "print(\"DD Params: {:,}\".format(discriminator.count_params()))\n",
        "print(\"DG Params: {:,}\".format(generator.count_params()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Jp8lN9U_r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn the downloaded directory of images into a dataset\n",
        "\n",
        "dataloader, n_batches = Trainer.image_dataset(\"alotofplansmodified\", batch_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOAZmQRScerk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for turning tensors into drawings\n",
        "to_image = transforms.ToPILImage()\n",
        "\n",
        "# Number of trips through the dataset\n",
        "n_epochs = 100\n",
        "\n",
        "# Objective functions\n",
        "discriminator_criterion = nn.BCELoss(reduction=\"mean\").cuda()\n",
        "generator_criterion = nn.BCELoss(reduction=\"mean\").cuda()\n",
        "\n",
        "# Learning rate\n",
        "lr = 5e-2\n",
        "\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "for epoch_number in range(n_epochs):\n",
        "    for batch_number, (data, label) in enumerate(dataloader):\n",
        "\n",
        "        # Data shape management\n",
        "        batch_size, channels, height, width = data.shape\n",
        "\n",
        "        # Move data to GPU\n",
        "        data = data.cuda()\n",
        "        # Change numeric range to [-1, 1]\n",
        "        data.sub_(.5).mul_(2)\n",
        "\n",
        "        # Make it differentiable\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Make labels to guide the discriminator\n",
        "        real_label = torch.zeros(batch_size, 2).cuda()\n",
        "        real_label[:, 0] = 1.0\n",
        "\n",
        "        fake_label = torch.zeros(batch_size, 2).cuda()\n",
        "        fake_label[:, 1] = 1.0\n",
        "\n",
        "        # Generate random vector to control style\n",
        "        z = torch.randn(batch_size, 512, 1, 1).cuda()\n",
        "\n",
        "        # Generate fake images\n",
        "\n",
        "        fake_images = generator(z, None, mode=\"generator\")\n",
        "\n",
        "        # Train discriminator on real\n",
        "        # Forwards\n",
        "        real_classification = discriminator(data, mode=\"discriminator\")\n",
        "        \n",
        "        #  Loss\n",
        "        real_loss = discriminator_criterion(real_classification, real_label)\n",
        "\n",
        "        # Backwards\n",
        "        real_loss.backward()\n",
        "\n",
        "        # Train on fake\n",
        "        # Forwards\n",
        "        fake_classification = discriminator(fake_images.detach(), mode=\"discriminator\")\n",
        "        \n",
        "        # Loss\n",
        "        fake_loss = discriminator_criterion(fake_classification, fake_label)\n",
        "\n",
        "        # Backwards\n",
        "        fake_loss.backward()\n",
        "\n",
        "        # Update weights based on loss attribution\n",
        "        discriminator_optimizer.step()\n",
        "        discriminator_optimizer.zero_grad()\n",
        "\n",
        "        # Train generator on how well it fools discriminator\n",
        "        # Forwards\n",
        "        gen_classification = discriminator(fake_images, mode=\"discriminator\")\n",
        "        \n",
        "        # Loss\n",
        "        gen_loss = discriminator_criterion(gen_classification, real_label)\n",
        "\n",
        "        # Backwards\n",
        "        gen_loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        generator_optimizer.step()\n",
        "        generator_optimizer.zero_grad()\n",
        "\n",
        "        # Progress tracking and printing\n",
        "        if batch_number % 20 == 0:\n",
        "            update_message =\\\n",
        "                \"Epoch: [{:4d}/{:4d}] Batch: [{:4d}/{:4d}]\\n\"+\\\n",
        "                \"Losses: [Real: {:.4f} Fake: {:.4f} Generator {:.4f}]\\n\"\n",
        "\n",
        "            update_message = update_message.format(\n",
        "                epoch_number + 1,\n",
        "                n_epochs,\n",
        "                batch_number,\n",
        "                n_batches,\n",
        "                real_loss.item(),\n",
        "                fake_loss.item(),\n",
        "                gen_loss.item(),\n",
        "                )\n",
        "\n",
        "            print(update_message)\n",
        "\n",
        "            n_rows = int(math.sqrt(batch_size))\n",
        "            \n",
        "            batch_image = vutils.make_grid(fake_images.clone().detach().cpu(), nrow=n_rows, normalize=True)\n",
        "\n",
        "            img = to_image(batch_image)\n",
        "            \n",
        "            plt.imshow(img)\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5rOKPqkWgFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}