{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as odict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Add:\n",
    "\n",
    "Sequences of stuff (list comprehensions)\n",
    "\n",
    "Tensor intro\n",
    "\n",
    "Drawing with tensors\n",
    "\n",
    "Math = Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences\n",
    "\n",
    "## Expansion and Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors are Drawings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math is Drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings:\n",
    "    LatentDimension = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Network\n",
    "\n",
    "The mapping network is stated to be a nonlinear function:\n",
    "\n",
    "$$f : Z \\rightarrow W$$\n",
    "\n",
    "The authors state that this function is implemented practically as a multilayer perceptron (MLP) with 8 layers and that both spaces $Z$ and $W$ are set to be 512-dimensional.\n",
    "\n",
    "We could state this more explicitly as:\n",
    "\n",
    "$$ Z, W \\in \\mathbb{R}^{512} $$\n",
    "\n",
    "All that this means is that both $Z$ and $W$ are vectors of real numbers that have 512 entries ( `[1.1, 2.65, 3.141, ..., 6.022]` ).\n",
    "\n",
    "### Multilayer Perceptron\n",
    "\n",
    "But what, exactly, is a \"multilayer perceptron\"?\n",
    "\n",
    "An MLP is a very simple kind of neural network that simply takes a vector input, multiplies it with a weight matrix to get another vector, and then repeats for some number of layers. Formally:\n",
    "\n",
    "$$ x \\in \\mathbb{R}^{1 \\times m} $$\n",
    "$$ w \\in \\mathbb{R}^{m \\times n} $$\n",
    "$$ y \\in \\mathbb{R}^{1 \\times n} $$\n",
    "\n",
    "This is essentially just a vector, matrix product. If $m \\gt n$ then the layer will be performing data reduction, if $m \\lt n$ then it will be performing data expansion. Notably, if the weight matrix $w$ is square, $x$ and $y$ will be the same dimension, and this is what is happening in the Mapping Network. There is also no mention of a nonlinearity applied to the Mapping Network in the paper, so our construction in code is very straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappingNetwork(nn.Sequential):\n",
    "    def __init__(self, layer_count=8, latent_dim=512):\n",
    "        super(MappingNetwork, self).__init__()\n",
    "\n",
    "        for layer_number in range(layer_count):\n",
    "            layer_name = \"linear_{}\".format(layer_number)\n",
    "            layer = nn.Linear(latent_dim, latent_dim)\n",
    "            self.add_module(layer_name, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Note\n",
    "\n",
    "$$ f \\sim mn $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis Network\n",
    "\n",
    "The authors' diagram of the Synthesis Network shows a repeating block of upsample, convolution, noise scaling/addition, and a function that they define called `AdaIN`.\n",
    "$$ W \\in \\mathbb{R}^n $$\n",
    "$$ Y \\in \\mathbb{R}^{2n} $$\n",
    "$$ A : W \\rightarrow Y $$\n",
    "\n",
    "$Y$ can be thought of as a style space where the scalar components are parameters that control both how strongly feature maps in $x$ are carried forward, and how much it is shifted around the style space.\n",
    "\n",
    "$$ AdaIN(x_i, y) = y_{s, i}\\frac{x_i - \\mu(x_i)}{\\sigma(x_i)} + y_{b, i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(nn.Module):\n",
    "    def __init__(self, in_features, w_dim=512):\n",
    "        super(A, self).__init__()\n",
    "        self.affine = nn.Linear(w_dim, 2 * in_features)\n",
    "    \n",
    "    def forward(self, w):\n",
    "        return self.affine(w).reshape(2, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(nn.Module):\n",
    "    def __init__(self, height, width, num_features):\n",
    "        super(B, self).__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.noise_image = torch.randn(1, 1, height, width)\n",
    "        \n",
    "        self.scaling_factors = torch.nn.Parameter(data=torch.randn(1, num_features, 1, 1), requires_grad=True)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.scaling_factors.expand(1, -1, self.height, self.width) * self.noise_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdaIN, self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        mu_x    = x.mean(dim=(0, 2, 3)).reshape(1, -1, 1, 1)\n",
    "        sigma_x = x.std(dim=(0, 2, 3)).reshape(1, -1, 1, 1)\n",
    "        \n",
    "        normed_x = (x - mu_x) / sigma_x\n",
    "        \n",
    "        y = y.reshape(2, -1, 1, 1)\n",
    "        \n",
    "        return (y[0, :] * x) + y[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PixelNorm\n",
    "From the [Progressive Growing of GANs paper](https://arxiv.org/pdf/1710.10196.pdf), section 4.2, the authors detail the per-pixel normalization function as:\n",
    "\n",
    "$$ b_{x, y} = \\frac{a_{x, y}}{\\sqrt{\\frac{1}{n}\\Sigma_{j=0}^{n-1}{(a^{j}_{x, y})^2 + \\epsilon}}} $$\n",
    "\n",
    "where $\\epsilon = 10^{-8}$ and $n$ is the number of feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 10 ** -8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        d = x.pow(2)\n",
    "        d = d.sum(dim=(1)) + self.epsilon\n",
    "        # substitute c for n to follow pytorch documentation (n, c, h, w)\n",
    "        d = d.mul(1 / c)\n",
    "        d = d.sqrt()\n",
    "        d = d.unsqueeze(1)\n",
    "\n",
    "        return x / d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, (3, 3), 1, 1)\n",
    "        self.conv.weight.data.normal_(0, 1)\n",
    "        self.conv.bias.data.fill_(0)\n",
    "        \n",
    "        self.norm = PixelNorm()\n",
    "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, height, width, w_dim=512):\n",
    "        super(SynthesisBlock, self).__init__()\n",
    "        \n",
    "        self.upsample = nn.UpsamplingBilinear2d((height, width))\n",
    "        self.conv0 =    ConvBlock(in_channels, out_channels)\n",
    "        self.b0 =       B(height, width, out_channels)\n",
    "        self.a0 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain0 =   AdaIN()\n",
    "        \n",
    "        self.conv1 =    ConvBlock(out_channels, out_channels)\n",
    "        self.b1 =       B(height, width, out_channels)\n",
    "        self.a1 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain1 =   AdaIN()\n",
    "    \n",
    "    def forward(self, tensor_dict):\n",
    "\n",
    "        x = tensor_dict[\"x\"]\n",
    "        w = tensor_dict[\"w\"]\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = self.conv0(x)\n",
    "        x = x + self.b0()\n",
    "        y = self.a0(w)\n",
    "        x = self.adain0(x, y)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = x + self.b1()\n",
    "        y = self.a1(w)\n",
    "        x = self.adain1(x, y)\n",
    "        \n",
    "        return {\"x\": x, \"w\": w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, height, width, w_dim=512):\n",
    "        super(InputBlock, self).__init__()\n",
    "        \n",
    "        self.conv0 =    ConvBlock(in_channels, out_channels)\n",
    "        self.b0 =       B(height, width, out_channels)\n",
    "        self.a0 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain0 =   AdaIN()\n",
    "        \n",
    "        self.b1 =       B(height, width, out_channels)\n",
    "        self.a1 =       A(out_channels, w_dim=w_dim)\n",
    "        self.adain1 =   AdaIN()\n",
    "    \n",
    "    def forward(self, tensor_dict):\n",
    "\n",
    "        x = tensor_dict[\"x\"]\n",
    "        w = tensor_dict[\"w\"]\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "        x = x + self.b0()\n",
    "        y = self.a0(w)\n",
    "        x = self.adain0(x, y)\n",
    "\n",
    "        x = x + self.b1()\n",
    "        y = self.a1(w)\n",
    "        x = self.adain1(x, y)\n",
    "        \n",
    "        return {\"x\": x, \"w\": w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(OutputBlock, self).__init__()\n",
    "        \n",
    "        self.to_rgb = nn.Conv2d(input_channels, 3, (1, 1))\n",
    "    \n",
    "    def forward(self, tensor_dict):\n",
    "        x = tensor_dict[\"x\"]\n",
    "        w = tensor_dict[\"w\"]\n",
    "        \n",
    "        x = self.to_rgb(x)\n",
    "        \n",
    "        return {\"x\": x, \"w\": w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGenerator(nn.Module):\n",
    "    def __init__(self, input_layer=None, layer_params=None, w_dim=512):\n",
    "        super(StyleGenerator, self).__init__()\n",
    "        \n",
    "        if input_layer == None:\n",
    "            input_layer = InputBlock(512, 512, 4, 4, w_dim=w_dim)\n",
    "        \n",
    "        self.input = input_layer\n",
    "\n",
    "        self.main = nn.Sequential()\n",
    "\n",
    "        if layer_params == None:\n",
    "            layer_params = [\n",
    "                (512, 512,    8,    8, w_dim),\n",
    "                (512, 512,   16,   16, w_dim),\n",
    "                (512, 512,   32,   32, w_dim),\n",
    "                (512, 256,   64,   64, w_dim),\n",
    "                (256, 128,  128,  128, w_dim),\n",
    "                (128,  64,  256,  256, w_dim),\n",
    "                ( 64,  32,  512,  512, w_dim),\n",
    "                ( 32,  16, 1024, 1024, w_dim),\n",
    "            ]\n",
    "        \n",
    "        self.layer_params = layer_params\n",
    "        \n",
    "        self.main_layer_count = len(self.layer_params)\n",
    "\n",
    "    def configure_progressive_train(self):\n",
    "        for child in self.main.children():\n",
    "            for p in child.parameters():\n",
    "                p.requires_grad = False\n",
    "                # Check that Progressive Growing of GANs actually freezes layers\n",
    "        \n",
    "        current_layer_count = len(list(self.main.children()))\n",
    "        \n",
    "        if len(self.layer_params) == 0:\n",
    "            return\n",
    "        \n",
    "        new_layer_params = self.layer_params.pop(0)\n",
    "        \n",
    "        final_out_channels = new_layer_params[1]\n",
    "        \n",
    "        self.main.add_module(\"sb_{}\".format(current_layer_count), SynthesisBlock(*new_layer_params))\n",
    "        print(\"Added block with params:{}\\n\".format(new_layer_params))\n",
    "        \n",
    "        self.output = OutputBlock(final_out_channels)\n",
    "\n",
    "    def forward(self, tensor_dict):\n",
    "        tensor_dict = self.input(tensor_dict)\n",
    "        tensor_dict = self.main(tensor_dict)\n",
    "\n",
    "        return self.output(tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MappingNetwork(\n",
      "  (linear_0): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_5): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_6): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (linear_7): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n",
      "StyleGenerator(\n",
      "  (input): InputBlock(\n",
      "    (conv0): ConvBlock(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): PixelNorm()\n",
      "      (act): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (b0): B()\n",
      "    (a0): A(\n",
      "      (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    )\n",
      "    (adain0): AdaIN()\n",
      "    (b1): B()\n",
      "    (a1): A(\n",
      "      (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    )\n",
      "    (adain1): AdaIN()\n",
      "  )\n",
      "  (main): Sequential()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mn = MappingNetwork()\n",
    "sg = StyleGenerator()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(mn)\n",
    "print(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StyleGenerator(\n",
       "  (input): InputBlock(\n",
       "    (conv0): ConvBlock(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm): PixelNorm()\n",
       "      (act): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (b0): B()\n",
       "    (a0): A(\n",
       "      (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "    (adain0): AdaIN()\n",
       "    (b1): B()\n",
       "    (a1): A(\n",
       "      (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "    (adain1): AdaIN()\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (sb_0): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(8, 8), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_1): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(16, 16), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_2): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(32, 32), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_3): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(64, 64), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_4): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(128, 128), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_5): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(256, 256), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_6): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(512, 512), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=64, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=64, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "    (sb_7): SynthesisBlock(\n",
       "      (upsample): UpsamplingBilinear2d(size=(1024, 1024), mode=bilinear)\n",
       "      (conv0): ConvBlock(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b0): B()\n",
       "      (a0): A(\n",
       "        (affine): Linear(in_features=512, out_features=32, bias=True)\n",
       "      )\n",
       "      (adain0): AdaIN()\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm): PixelNorm()\n",
       "        (act): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "      (b1): B()\n",
       "      (a1): A(\n",
       "        (affine): Linear(in_features=512, out_features=32, bias=True)\n",
       "      )\n",
       "      (adain1): AdaIN()\n",
       "    )\n",
       "  )\n",
       "  (output): OutputBlock(\n",
       "    (to_rgb): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.configure_progressive_train()\n",
    "sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3281, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 512, 4, 4, requires_grad=True)\n",
    "z = torch.randn(1, 512, requires_grad=True)\n",
    "\n",
    "w = mn(z)\n",
    "\n",
    "\n",
    "tensor_dict = {\"x\": x, \"w\": w}\n",
    "\n",
    "output = sg(tensor_dict)\n",
    "\n",
    "loss = criterion(torch.ones_like(output[\"x\"]), output[\"x\"])\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.6959e-09)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Sequential()\n",
    "s.add_module(\"a\", nn.Linear(4, 4))\n",
    "s.add_module(\"b\", nn.Linear(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in s.children():\n",
    "    for p in child.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "\n",
    "a.pop(0)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
